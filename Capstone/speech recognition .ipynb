{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdal_000\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.models import Sequential \n",
    "from keras.layers import  Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "file_path=\"audio\"\n",
    "max_pad_length=40\n",
    "random_state=42\n",
    "labels=['stop', 'left', 'unknown', 'off', 'yes', 'up', 'on', 'down', 'no', 'go', 'right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_wavfile(path=\"audio/go/0d53e045_nohash_1.wav\"):\n",
    "    \n",
    "    sample_rate, samples = wavfile.read(path)\n",
    "    frequencies, times, spectrogram = signal.spectrogram(samples, sample_rate)\n",
    "    plt.pcolormesh(times, frequencies, spectrogram)\n",
    "    plt.imshow(spectrogram)\n",
    "    plt.ylabel('Frequecy [HZ]')\n",
    "    plt.xlabel('Time [sec]')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_wave_to_mfcc(filePath):\n",
    "    wav, sr =librosa.load(filePath, mono = True, sr=None)\n",
    "    mfcc = librosa.feature.mfcc(wav, sr=sr)\n",
    "    ##padding\n",
    "    mfcc_feature = np.pad(mfcc, pad_width=((0, 0), (0, max_pad_length - mfcc.shape[1])), mode='constant')\n",
    "    return mfcc_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(path=file_path):\n",
    "    return os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_mfcc_files(path=file_path):\n",
    "    labels = get_labels(path)\n",
    "    #print(labels)\n",
    "    for label in labels:\n",
    "        mfcc_features=[]\n",
    "        audfiles=[path+'/'+label+'/'+aud for aud in os.listdir(path+'/'+label)]\n",
    "        for audio in audfiles:\n",
    "            mfcc_features.append(convert_wave_to_mfcc(audio))\n",
    "        #print(len(mfcc_vectors))\n",
    "        np.save(label+'.npy', mfcc_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stop',\n",
       " 'left',\n",
       " 'unknown',\n",
       " 'off',\n",
       " 'yes',\n",
       " 'up',\n",
       " 'on',\n",
       " 'down',\n",
       " 'no',\n",
       " 'go',\n",
       " 'right']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_testing_set(path=file_path,test_size=.3):\n",
    "    labels = get_labels(path)\n",
    "    #features=[]\n",
    "    features=np.load(labels[0]+'.npy')\n",
    "    classes=np.zeros(features.shape[0])\n",
    "    #for i,label in zip(range(0,len(labels)-1),labels):\n",
    "    for i in range(1,len(labels)):\n",
    "        x=np.load(labels[i]+'.npy')\n",
    "        features=np.vstack((features,x))\n",
    "        classes=np.append(classes, np.full(x.shape[0], fill_value= (i)))\n",
    "    return train_test_split(features, classes, test_size= test_size, random_state=random_state, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = generate_training_testing_set()\n",
    "#print(X_train.shape)\n",
    "model =Sequential()\n",
    "model.add(Conv2D(32,kernel_size=(2,2),activation='relu',input_shape=(20,40,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Conv2D(64,kernel_size=(2,2),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Conv2D(128,kernel_size=(2,2),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(11,activation='softmax'))\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.adadelta(),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17003 7287\n"
     ]
    }
   ],
   "source": [
    "print ( len(X_train), len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11902 samples, validate on 5101 samples\n",
      "Epoch 1/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 6.4900 - acc: 0.0972Epoch 00001: val_loss improved from inf to 2.39389, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 2s 156us/step - loss: 6.4468 - acc: 0.0974 - val_loss: 2.3939 - val_acc: 0.0992\n",
      "Epoch 2/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 2.4492 - acc: 0.1028Epoch 00002: val_loss improved from 2.39389 to 2.38966, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 2.4484 - acc: 0.1028 - val_loss: 2.3897 - val_acc: 0.0972\n",
      "Epoch 3/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 2.4026 - acc: 0.0980Epoch 00003: val_loss improved from 2.38966 to 2.38587, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 2.4026 - acc: 0.0981 - val_loss: 2.3859 - val_acc: 0.0931\n",
      "Epoch 4/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 2.3946 - acc: 0.0983Epoch 00004: val_loss improved from 2.38587 to 2.38268, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 2.3947 - acc: 0.0987 - val_loss: 2.3827 - val_acc: 0.0927\n",
      "Epoch 5/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 2.3839 - acc: 0.0996Epoch 00005: val_loss improved from 2.38268 to 2.38002, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 2.3837 - acc: 0.1003 - val_loss: 2.3800 - val_acc: 0.0931\n",
      "Epoch 6/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 2.3813 - acc: 0.0969Epoch 00006: val_loss improved from 2.38002 to 2.37793, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 2.3813 - acc: 0.0971 - val_loss: 2.3779 - val_acc: 0.0929\n",
      "Epoch 7/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 2.3785 - acc: 0.0982Epoch 00007: val_loss improved from 2.37793 to 2.37620, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 2.3784 - acc: 0.0982 - val_loss: 2.3762 - val_acc: 0.0927\n",
      "Epoch 8/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 2.3757 - acc: 0.1010Epoch 00008: val_loss improved from 2.37620 to 2.37478, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 2.3757 - acc: 0.1012 - val_loss: 2.3748 - val_acc: 0.0929\n",
      "Epoch 9/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 2.3732 - acc: 0.1037Epoch 00009: val_loss improved from 2.37478 to 2.37360, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 2.3732 - acc: 0.1038 - val_loss: 2.3736 - val_acc: 0.0929\n",
      "Epoch 10/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 2.3728 - acc: 0.1021Epoch 00010: val_loss improved from 2.37360 to 2.37261, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 100us/step - loss: 2.3727 - acc: 0.1017 - val_loss: 2.3726 - val_acc: 0.0929\n",
      "Epoch 11/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 2.3720 - acc: 0.1021Epoch 00011: val_loss improved from 2.37261 to 2.37178, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 2.3721 - acc: 0.1018 - val_loss: 2.3718 - val_acc: 0.0929\n",
      "Epoch 12/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 2.3699 - acc: 0.1021Epoch 00012: val_loss improved from 2.37178 to 2.37111, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 2.3697 - acc: 0.1018 - val_loss: 2.3711 - val_acc: 0.0925\n",
      "Epoch 13/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 2.3693 - acc: 0.1024Epoch 00013: val_loss improved from 2.37111 to 2.37021, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 2.3692 - acc: 0.1030 - val_loss: 2.3702 - val_acc: 0.0933\n",
      "Epoch 14/250\n",
      "11520/11902 [============================>.] - ETA: 0s - loss: 2.3687 - acc: 0.1002Epoch 00014: val_loss improved from 2.37021 to 2.36999, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 2.3689 - acc: 0.1006 - val_loss: 2.3700 - val_acc: 0.0929\n",
      "Epoch 15/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 2.3674 - acc: 0.1017Epoch 00015: val_loss improved from 2.36999 to 2.36945, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 2.3674 - acc: 0.1016 - val_loss: 2.3695 - val_acc: 0.0927\n",
      "Epoch 16/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 2.3671 - acc: 0.1024Epoch 00016: val_loss improved from 2.36945 to 2.36901, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 2.3672 - acc: 0.1026 - val_loss: 2.3690 - val_acc: 0.0931\n",
      "Epoch 17/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 2.3665 - acc: 0.1020Epoch 00017: val_loss improved from 2.36901 to 2.36885, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 2.3662 - acc: 0.1020 - val_loss: 2.3689 - val_acc: 0.0927\n",
      "Epoch 18/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 2.3652 - acc: 0.1016Epoch 00018: val_loss improved from 2.36885 to 2.36852, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 2.3655 - acc: 0.1019 - val_loss: 2.3685 - val_acc: 0.0931\n",
      "Epoch 19/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 2.3661 - acc: 0.1016Epoch 00019: val_loss improved from 2.36852 to 2.36819, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 2.3661 - acc: 0.1015 - val_loss: 2.3682 - val_acc: 0.0931\n",
      "Epoch 20/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 2.3657 - acc: 0.1022Epoch 00020: val_loss improved from 2.36819 to 2.36774, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 2.3656 - acc: 0.1022 - val_loss: 2.3677 - val_acc: 0.0931\n",
      "Epoch 21/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 2.3635 - acc: 0.1019Epoch 00021: val_loss improved from 2.36774 to 2.36743, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 2.3634 - acc: 0.1023 - val_loss: 2.3674 - val_acc: 0.0935\n",
      "Epoch 22/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 2.3637 - acc: 0.1073Epoch 00022: val_loss improved from 2.36743 to 2.34714, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 2.3635 - acc: 0.1071 - val_loss: 2.3471 - val_acc: 0.1513\n",
      "Epoch 23/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 2.3447 - acc: 0.134 - ETA: 0s - loss: 2.3419 - acc: 0.1360Epoch 00023: val_loss improved from 2.34714 to 2.26666, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 2.3414 - acc: 0.1359 - val_loss: 2.2667 - val_acc: 0.1784\n",
      "Epoch 24/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 2.2838 - acc: 0.1633Epoch 00024: val_loss improved from 2.26666 to 2.21329, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 2.2834 - acc: 0.1636 - val_loss: 2.2133 - val_acc: 0.1892\n",
      "Epoch 25/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 2.2171 - acc: 0.1871Epoch 00025: val_loss improved from 2.21329 to 2.05910, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 2.2161 - acc: 0.1873 - val_loss: 2.0591 - val_acc: 0.2452\n",
      "Epoch 26/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 2.0956 - acc: 0.2278Epoch 00026: val_loss improved from 2.05910 to 1.91435, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 2.0954 - acc: 0.2276 - val_loss: 1.9144 - val_acc: 0.2860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 1.9822 - acc: 0.2633Epoch 00027: val_loss improved from 1.91435 to 1.78912, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 1.9805 - acc: 0.2647 - val_loss: 1.7891 - val_acc: 0.3448\n",
      "Epoch 28/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 1.8600 - acc: 0.3259Epoch 00028: val_loss improved from 1.78912 to 1.62885, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 1.8581 - acc: 0.3268 - val_loss: 1.6288 - val_acc: 0.4105\n",
      "Epoch 29/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 1.7611 - acc: 0.3678Epoch 00029: val_loss improved from 1.62885 to 1.42684, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 1.7590 - acc: 0.3683 - val_loss: 1.4268 - val_acc: 0.5324\n",
      "Epoch 30/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 1.6409 - acc: 0.4117Epoch 00030: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 1.6431 - acc: 0.4105 - val_loss: 1.4401 - val_acc: 0.5075\n",
      "Epoch 31/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 1.5364 - acc: 0.4580Epoch 00031: val_loss improved from 1.42684 to 1.23304, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 1.5356 - acc: 0.4585 - val_loss: 1.2330 - val_acc: 0.6179\n",
      "Epoch 32/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 1.4315 - acc: 0.4930Epoch 00032: val_loss improved from 1.23304 to 1.19942, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 1.4304 - acc: 0.4938 - val_loss: 1.1994 - val_acc: 0.5766\n",
      "Epoch 33/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 1.3545 - acc: 0.5256Epoch 00033: val_loss improved from 1.19942 to 1.03873, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 1.3541 - acc: 0.5257 - val_loss: 1.0387 - val_acc: 0.6679\n",
      "Epoch 34/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 1.2779 - acc: 0.5563Epoch 00034: val_loss improved from 1.03873 to 0.96663, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 1.2793 - acc: 0.5555 - val_loss: 0.9666 - val_acc: 0.6885\n",
      "Epoch 35/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 1.2269 - acc: 0.5774Epoch 00035: val_loss improved from 0.96663 to 0.94213, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 1.2256 - acc: 0.5780 - val_loss: 0.9421 - val_acc: 0.6883\n",
      "Epoch 36/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 1.1598 - acc: 0.5951Epoch 00036: val_loss improved from 0.94213 to 0.87389, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 1.1597 - acc: 0.5950 - val_loss: 0.8739 - val_acc: 0.7222\n",
      "Epoch 37/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 1.1329 - acc: 0.6151Epoch 00037: val_loss improved from 0.87389 to 0.81333, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 103us/step - loss: 1.1311 - acc: 0.6152 - val_loss: 0.8133 - val_acc: 0.7457\n",
      "Epoch 38/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 1.0673 - acc: 0.6333Epoch 00038: val_loss improved from 0.81333 to 0.77735, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 1.0665 - acc: 0.6338 - val_loss: 0.7773 - val_acc: 0.7502\n",
      "Epoch 39/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 1.0303 - acc: 0.6406Epoch 00039: val_loss improved from 0.77735 to 0.74581, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 1.0303 - acc: 0.6410 - val_loss: 0.7458 - val_acc: 0.7691\n",
      "Epoch 40/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 1.0092 - acc: 0.652 - ETA: 0s - loss: 1.0069 - acc: 0.6525Epoch 00040: val_loss improved from 0.74581 to 0.71710, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 1.0054 - acc: 0.6528 - val_loss: 0.7171 - val_acc: 0.7663\n",
      "Epoch 41/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.9685 - acc: 0.6625Epoch 00041: val_loss improved from 0.71710 to 0.70300, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.9678 - acc: 0.6628 - val_loss: 0.7030 - val_acc: 0.7822\n",
      "Epoch 42/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.9361 - acc: 0.6797Epoch 00042: val_loss improved from 0.70300 to 0.69531, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.9371 - acc: 0.6789 - val_loss: 0.6953 - val_acc: 0.7685\n",
      "Epoch 43/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.9050 - acc: 0.6884Epoch 00043: val_loss improved from 0.69531 to 0.65351, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 0.9072 - acc: 0.6873 - val_loss: 0.6535 - val_acc: 0.7896\n",
      "Epoch 44/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.8994 - acc: 0.6896- ETA: 0s - loss: 0.8854 - acc: Epoch 00044: val_loss improved from 0.65351 to 0.64639, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 0.8988 - acc: 0.6901 - val_loss: 0.6464 - val_acc: 0.7951\n",
      "Epoch 45/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.8703 - acc: 0.7029Epoch 00045: val_loss improved from 0.64639 to 0.63008, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 100us/step - loss: 0.8696 - acc: 0.7034 - val_loss: 0.6301 - val_acc: 0.7963\n",
      "Epoch 46/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.8480 - acc: 0.7098Epoch 00046: val_loss improved from 0.63008 to 0.60913, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 0.8491 - acc: 0.7098 - val_loss: 0.6091 - val_acc: 0.8042\n",
      "Epoch 47/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.8194 - acc: 0.7205Epoch 00047: val_loss improved from 0.60913 to 0.57274, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.8203 - acc: 0.7204 - val_loss: 0.5727 - val_acc: 0.8179\n",
      "Epoch 48/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.8072 - acc: 0.7284- ETA: 0s - loss: 0.8518 - acEpoch 00048: val_loss improved from 0.57274 to 0.56387, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.8075 - acc: 0.7279 - val_loss: 0.5639 - val_acc: 0.8218\n",
      "Epoch 49/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.7893 - acc: 0.7319Epoch 00049: val_loss improved from 0.56387 to 0.56327, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.7890 - acc: 0.7321 - val_loss: 0.5633 - val_acc: 0.8194\n",
      "Epoch 50/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.7845 - acc: 0.7346Epoch 00050: val_loss improved from 0.56327 to 0.54895, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.7850 - acc: 0.7345 - val_loss: 0.5489 - val_acc: 0.8257\n",
      "Epoch 51/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.7639 - acc: 0.7444Epoch 00051: val_loss improved from 0.54895 to 0.52332, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 0.7633 - acc: 0.7443 - val_loss: 0.5233 - val_acc: 0.8308\n",
      "Epoch 52/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.7509 - acc: 0.7407Epoch 00052: val_loss improved from 0.52332 to 0.51869, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 0.7507 - acc: 0.7412 - val_loss: 0.5187 - val_acc: 0.8318\n",
      "Epoch 53/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.7383 - acc: 0.7457Epoch 00053: val_loss improved from 0.51869 to 0.51361, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.7398 - acc: 0.7447 - val_loss: 0.5136 - val_acc: 0.8377\n",
      "Epoch 54/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.7232 - acc: 0.7531Epoch 00054: val_loss improved from 0.51361 to 0.50331, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.7247 - acc: 0.7531 - val_loss: 0.5033 - val_acc: 0.8432\n",
      "Epoch 55/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.7062 - acc: 0.7576- ETA: 0s - loss: 0.7108 - acc: 0.Epoch 00055: val_loss improved from 0.50331 to 0.49110, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.7057 - acc: 0.7580 - val_loss: 0.4911 - val_acc: 0.8459\n",
      "Epoch 56/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.6982 - acc: 0.7608Epoch 00056: val_loss improved from 0.49110 to 0.48301, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 0.7006 - acc: 0.7598 - val_loss: 0.4830 - val_acc: 0.8467\n",
      "Epoch 57/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.6883 - acc: 0.7679Epoch 00057: val_loss improved from 0.48301 to 0.47534, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.6877 - acc: 0.7679 - val_loss: 0.4753 - val_acc: 0.8479\n",
      "Epoch 58/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.6923 - acc: 0.7660Epoch 00058: val_loss improved from 0.47534 to 0.46581, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.6913 - acc: 0.7663 - val_loss: 0.4658 - val_acc: 0.8532\n",
      "Epoch 59/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.6721 - acc: 0.7735Epoch 00059: val_loss improved from 0.46581 to 0.44382, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.6710 - acc: 0.7739 - val_loss: 0.4438 - val_acc: 0.8590\n",
      "Epoch 60/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.6618 - acc: 0.7791Epoch 00060: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.6627 - acc: 0.7794 - val_loss: 0.4453 - val_acc: 0.8547\n",
      "Epoch 61/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.6455 - acc: 0.7842Epoch 00061: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.6452 - acc: 0.7844 - val_loss: 0.4487 - val_acc: 0.8547\n",
      "Epoch 62/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.6456 - acc: 0.7829Epoch 00062: val_loss improved from 0.44382 to 0.43432, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.6454 - acc: 0.7835 - val_loss: 0.4343 - val_acc: 0.8626\n",
      "Epoch 63/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.6419 - acc: 0.7835Epoch 00063: val_loss improved from 0.43432 to 0.42980, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.6425 - acc: 0.7835 - val_loss: 0.4298 - val_acc: 0.8624\n",
      "Epoch 64/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.6106 - acc: 0.7945Epoch 00064: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.6108 - acc: 0.7944 - val_loss: 0.4346 - val_acc: 0.8622\n",
      "Epoch 65/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.6166 - acc: 0.7955Epoch 00065: val_loss improved from 0.42980 to 0.41926, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 0.6155 - acc: 0.7954 - val_loss: 0.4193 - val_acc: 0.8667\n",
      "Epoch 66/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.6111 - acc: 0.7929Epoch 00066: val_loss improved from 0.41926 to 0.41716, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.6121 - acc: 0.7926 - val_loss: 0.4172 - val_acc: 0.8657\n",
      "Epoch 67/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.6068 - acc: 0.7938Epoch 00067: val_loss improved from 0.41716 to 0.41246, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.6073 - acc: 0.7936 - val_loss: 0.4125 - val_acc: 0.8675\n",
      "Epoch 68/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.5787 - acc: 0.8038Epoch 00068: val_loss improved from 0.41246 to 0.40981, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.5798 - acc: 0.8033 - val_loss: 0.4098 - val_acc: 0.8708\n",
      "Epoch 69/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.5841 - acc: 0.8010Epoch 00069: val_loss improved from 0.40981 to 0.40181, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.5825 - acc: 0.8015 - val_loss: 0.4018 - val_acc: 0.8687\n",
      "Epoch 70/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.5734 - acc: 0.8044Epoch 00070: val_loss improved from 0.40181 to 0.39614, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.5716 - acc: 0.8053 - val_loss: 0.3961 - val_acc: 0.8751\n",
      "Epoch 71/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.5683 - acc: 0.8073Epoch 00071: val_loss improved from 0.39614 to 0.39520, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.5690 - acc: 0.8074 - val_loss: 0.3952 - val_acc: 0.8714\n",
      "Epoch 72/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.5480 - acc: 0.8153- ETA: 0s - loss: 0.5492 - acc: 0.814Epoch 00072: val_loss improved from 0.39520 to 0.38637, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.5500 - acc: 0.8152 - val_loss: 0.3864 - val_acc: 0.8732\n",
      "Epoch 73/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.5499 - acc: 0.8142Epoch 00073: val_loss improved from 0.38637 to 0.38086, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.5496 - acc: 0.8141 - val_loss: 0.3809 - val_acc: 0.8773\n",
      "Epoch 74/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.5529 - acc: 0.8106Epoch 00074: val_loss improved from 0.38086 to 0.37152, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 0.5523 - acc: 0.8106 - val_loss: 0.3715 - val_acc: 0.8822\n",
      "Epoch 75/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.5400 - acc: 0.8167Epoch 00075: val_loss improved from 0.37152 to 0.36771, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.5391 - acc: 0.8167 - val_loss: 0.3677 - val_acc: 0.8808\n",
      "Epoch 76/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.5265 - acc: 0.8184Epoch 00076: val_loss improved from 0.36771 to 0.36644, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.5251 - acc: 0.8188 - val_loss: 0.3664 - val_acc: 0.8818\n",
      "Epoch 77/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.5247 - acc: 0.8224Epoch 00077: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.5252 - acc: 0.8223 - val_loss: 0.3686 - val_acc: 0.8822\n",
      "Epoch 78/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.5266 - acc: 0.8252Epoch 00078: val_loss improved from 0.36644 to 0.36545, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 0.5258 - acc: 0.8253 - val_loss: 0.3654 - val_acc: 0.8826\n",
      "Epoch 79/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.5210 - acc: 0.8245Epoch 00079: val_loss improved from 0.36545 to 0.35776, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 103us/step - loss: 0.5202 - acc: 0.8242 - val_loss: 0.3578 - val_acc: 0.8845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.5106 - acc: 0.8293Epoch 00080: val_loss improved from 0.35776 to 0.35207, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 0.5110 - acc: 0.8293 - val_loss: 0.3521 - val_acc: 0.8857\n",
      "Epoch 81/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.5116 - acc: 0.8254Epoch 00081: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.5119 - acc: 0.8251 - val_loss: 0.3602 - val_acc: 0.8810\n",
      "Epoch 82/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.5028 - acc: 0.8325Epoch 00082: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.5032 - acc: 0.8324 - val_loss: 0.3555 - val_acc: 0.8832\n",
      "Epoch 83/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.4939 - acc: 0.8292Epoch 00083: val_loss improved from 0.35207 to 0.34134, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.4935 - acc: 0.8292 - val_loss: 0.3413 - val_acc: 0.8894\n",
      "Epoch 84/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.4979 - acc: 0.8309Epoch 00084: val_loss improved from 0.34134 to 0.34034, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.4981 - acc: 0.8305 - val_loss: 0.3403 - val_acc: 0.8912\n",
      "Epoch 85/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.4779 - acc: 0.8376Epoch 00085: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 100us/step - loss: 0.4776 - acc: 0.8373 - val_loss: 0.3412 - val_acc: 0.8896\n",
      "Epoch 86/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.4835 - acc: 0.8331Epoch 00086: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 100us/step - loss: 0.4844 - acc: 0.8327 - val_loss: 0.3450 - val_acc: 0.8890\n",
      "Epoch 87/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.4812 - acc: 0.8357Epoch 00087: val_loss improved from 0.34034 to 0.33929, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 100us/step - loss: 0.4805 - acc: 0.8360 - val_loss: 0.3393 - val_acc: 0.8916\n",
      "Epoch 88/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.4599 - acc: 0.8428Epoch 00088: val_loss improved from 0.33929 to 0.33270, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.4610 - acc: 0.8425 - val_loss: 0.3327 - val_acc: 0.8920\n",
      "Epoch 89/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.4737 - acc: 0.8406Epoch 00089: val_loss improved from 0.33270 to 0.32915, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.4735 - acc: 0.8407 - val_loss: 0.3291 - val_acc: 0.8945\n",
      "Epoch 90/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.4621 - acc: 0.8443Epoch 00090: val_loss improved from 0.32915 to 0.32666, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 0.4614 - acc: 0.8444 - val_loss: 0.3267 - val_acc: 0.8936\n",
      "Epoch 91/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.4652 - acc: 0.8412Epoch 00091: val_loss improved from 0.32666 to 0.32077, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.4642 - acc: 0.8414 - val_loss: 0.3208 - val_acc: 0.8955\n",
      "Epoch 92/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.4605 - acc: 0.8464Epoch 00092: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 100us/step - loss: 0.4599 - acc: 0.8464 - val_loss: 0.3233 - val_acc: 0.8934\n",
      "Epoch 93/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.4448 - acc: 0.8530Epoch 00093: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.4449 - acc: 0.8529 - val_loss: 0.3287 - val_acc: 0.8941\n",
      "Epoch 94/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.4389 - acc: 0.8505Epoch 00094: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.4386 - acc: 0.8505 - val_loss: 0.3214 - val_acc: 0.8937\n",
      "Epoch 95/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.4521 - acc: 0.8426- ETA: 0s - loss: 0.4476 - acc: 0.84Epoch 00095: val_loss improved from 0.32077 to 0.31946, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.4509 - acc: 0.8431 - val_loss: 0.3195 - val_acc: 0.8959\n",
      "Epoch 96/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.4482 - acc: 0.8461Epoch 00096: val_loss improved from 0.31946 to 0.31717, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.4495 - acc: 0.8457 - val_loss: 0.3172 - val_acc: 0.9014\n",
      "Epoch 97/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.4448 - acc: 0.8518Epoch 00097: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.4452 - acc: 0.8517 - val_loss: 0.3276 - val_acc: 0.8926\n",
      "Epoch 98/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.4285 - acc: 0.8556Epoch 00098: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.4287 - acc: 0.8554 - val_loss: 0.3213 - val_acc: 0.8941\n",
      "Epoch 99/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.4279 - acc: 0.8573Epoch 00099: val_loss improved from 0.31717 to 0.31117, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 0.4295 - acc: 0.8569 - val_loss: 0.3112 - val_acc: 0.8994\n",
      "Epoch 100/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.4251 - acc: 0.8560Epoch 00100: val_loss improved from 0.31117 to 0.30670, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 0.4228 - acc: 0.8569 - val_loss: 0.3067 - val_acc: 0.9032\n",
      "Epoch 101/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.4168 - acc: 0.8556Epoch 00101: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.4170 - acc: 0.8554 - val_loss: 0.3082 - val_acc: 0.8996\n",
      "Epoch 102/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.4063 - acc: 0.8654Epoch 00102: val_loss improved from 0.30670 to 0.30639, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 0.4069 - acc: 0.8648 - val_loss: 0.3064 - val_acc: 0.9020\n",
      "Epoch 103/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.4077 - acc: 0.8637Epoch 00103: val_loss improved from 0.30639 to 0.30250, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.4069 - acc: 0.8639 - val_loss: 0.3025 - val_acc: 0.9026\n",
      "Epoch 104/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.4104 - acc: 0.8613Epoch 00104: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.4106 - acc: 0.8610 - val_loss: 0.3055 - val_acc: 0.8994\n",
      "Epoch 105/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.4203 - acc: 0.8597Epoch 00105: val_loss improved from 0.30250 to 0.30193, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.4212 - acc: 0.8594 - val_loss: 0.3019 - val_acc: 0.9000\n",
      "Epoch 106/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.4117 - acc: 0.8571Epoch 00106: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.4114 - acc: 0.8573 - val_loss: 0.3048 - val_acc: 0.8996\n",
      "Epoch 107/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.4014 - acc: 0.8634Epoch 00107: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.4014 - acc: 0.8632 - val_loss: 0.3023 - val_acc: 0.9006\n",
      "Epoch 108/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.4041 - acc: 0.8608Epoch 00108: val_loss improved from 0.30193 to 0.30106, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 0.4042 - acc: 0.8608 - val_loss: 0.3011 - val_acc: 0.9030\n",
      "Epoch 109/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.3913 - acc: 0.8666Epoch 00109: val_loss improved from 0.30106 to 0.29097, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 0.3914 - acc: 0.8668 - val_loss: 0.2910 - val_acc: 0.9075\n",
      "Epoch 110/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.3924 - acc: 0.8677Epoch 00110: val_loss improved from 0.29097 to 0.29030, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 0.3916 - acc: 0.8679 - val_loss: 0.2903 - val_acc: 0.9067\n",
      "Epoch 111/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.3862 - acc: 0.8703Epoch 00111: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.3856 - acc: 0.8709 - val_loss: 0.2971 - val_acc: 0.9032\n",
      "Epoch 112/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.3851 - acc: 0.8666Epoch 00112: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.3867 - acc: 0.8662 - val_loss: 0.2973 - val_acc: 0.9035\n",
      "Epoch 113/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.3885 - acc: 0.8672Epoch 00113: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.3884 - acc: 0.8669 - val_loss: 0.2918 - val_acc: 0.9047\n",
      "Epoch 114/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.3856 - acc: 0.8714Epoch 00114: val_loss improved from 0.29030 to 0.28350, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 0.3851 - acc: 0.8716 - val_loss: 0.2835 - val_acc: 0.9110\n",
      "Epoch 115/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.3836 - acc: 0.8673Epoch 00115: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.3835 - acc: 0.8674 - val_loss: 0.2905 - val_acc: 0.9084\n",
      "Epoch 116/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.3758 - acc: 0.8747Epoch 00116: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 98us/step - loss: 0.3756 - acc: 0.8748 - val_loss: 0.2900 - val_acc: 0.9067\n",
      "Epoch 117/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.3700 - acc: 0.8687Epoch 00117: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 98us/step - loss: 0.3689 - acc: 0.8688 - val_loss: 0.2892 - val_acc: 0.9067\n",
      "Epoch 118/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.3605 - acc: 0.8797Epoch 00118: val_loss improved from 0.28350 to 0.28167, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 0.3595 - acc: 0.8798 - val_loss: 0.2817 - val_acc: 0.9081\n",
      "Epoch 119/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.3719 - acc: 0.8753Epoch 00119: val_loss improved from 0.28167 to 0.27965, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 0.3711 - acc: 0.8756 - val_loss: 0.2796 - val_acc: 0.9114\n",
      "Epoch 120/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.3661 - acc: 0.8749Epoch 00120: val_loss improved from 0.27965 to 0.27871, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.3666 - acc: 0.8746 - val_loss: 0.2787 - val_acc: 0.9102\n",
      "Epoch 121/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.3677 - acc: 0.8737Epoch 00121: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.3675 - acc: 0.8737 - val_loss: 0.2808 - val_acc: 0.9090\n",
      "Epoch 122/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.3636 - acc: 0.8765Epoch 00122: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.3641 - acc: 0.8764 - val_loss: 0.2882 - val_acc: 0.9067\n",
      "Epoch 123/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.3585 - acc: 0.8764Epoch 00123: val_loss improved from 0.27871 to 0.27527, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 100us/step - loss: 0.3578 - acc: 0.8764 - val_loss: 0.2753 - val_acc: 0.9116\n",
      "Epoch 124/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.3604 - acc: 0.8792Epoch 00124: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.3600 - acc: 0.8790 - val_loss: 0.2763 - val_acc: 0.9116\n",
      "Epoch 125/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.3521 - acc: 0.8790Epoch 00125: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.3523 - acc: 0.8790 - val_loss: 0.2758 - val_acc: 0.9112\n",
      "Epoch 126/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.3533 - acc: 0.8794Epoch 00126: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 98us/step - loss: 0.3522 - acc: 0.8799 - val_loss: 0.2787 - val_acc: 0.9120\n",
      "Epoch 127/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.3481 - acc: 0.8804Epoch 00127: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 98us/step - loss: 0.3487 - acc: 0.8803 - val_loss: 0.2753 - val_acc: 0.9120\n",
      "Epoch 128/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.3524 - acc: 0.8821Epoch 00128: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 98us/step - loss: 0.3527 - acc: 0.8820 - val_loss: 0.2784 - val_acc: 0.9108\n",
      "Epoch 129/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.3525 - acc: 0.8804Epoch 00129: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 98us/step - loss: 0.3523 - acc: 0.8806 - val_loss: 0.2755 - val_acc: 0.9096\n",
      "Epoch 130/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.3397 - acc: 0.8849Epoch 00130: val_loss improved from 0.27527 to 0.26840, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.3399 - acc: 0.8848 - val_loss: 0.2684 - val_acc: 0.9135\n",
      "Epoch 131/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.3433 - acc: 0.8843Epoch 00131: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 98us/step - loss: 0.3433 - acc: 0.8840 - val_loss: 0.2711 - val_acc: 0.9153\n",
      "Epoch 132/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.3485 - acc: 0.8812Epoch 00132: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 98us/step - loss: 0.3482 - acc: 0.8815 - val_loss: 0.2737 - val_acc: 0.9137\n",
      "Epoch 133/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.3376 - acc: 0.8832Epoch 00133: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 98us/step - loss: 0.3371 - acc: 0.8834 - val_loss: 0.2767 - val_acc: 0.9106\n",
      "Epoch 134/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.3412 - acc: 0.8832Epoch 00134: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.3413 - acc: 0.8833 - val_loss: 0.2755 - val_acc: 0.9128\n",
      "Epoch 135/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.3321 - acc: 0.8856Epoch 00135: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 98us/step - loss: 0.3314 - acc: 0.8858 - val_loss: 0.2726 - val_acc: 0.9130\n",
      "Epoch 136/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.3427 - acc: 0.8851Epoch 00136: val_loss improved from 0.26840 to 0.26548, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.3408 - acc: 0.8856 - val_loss: 0.2655 - val_acc: 0.9137\n",
      "Epoch 137/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.3334 - acc: 0.8877Epoch 00137: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 100us/step - loss: 0.3335 - acc: 0.8876 - val_loss: 0.2740 - val_acc: 0.9088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.3217 - acc: 0.8894Epoch 00138: val_loss improved from 0.26548 to 0.26242, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.3226 - acc: 0.8896 - val_loss: 0.2624 - val_acc: 0.9183\n",
      "Epoch 139/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.3363 - acc: 0.8854Epoch 00139: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.3363 - acc: 0.8854 - val_loss: 0.2638 - val_acc: 0.9157\n",
      "Epoch 140/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.3207 - acc: 0.8882Epoch 00140: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.3198 - acc: 0.8888 - val_loss: 0.2713 - val_acc: 0.9134\n",
      "Epoch 141/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.3239 - acc: 0.8899Epoch 00141: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.3242 - acc: 0.8894 - val_loss: 0.2674 - val_acc: 0.9145\n",
      "Epoch 142/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.3147 - acc: 0.8944Epoch 00142: val_loss improved from 0.26242 to 0.25905, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.3139 - acc: 0.8949 - val_loss: 0.2590 - val_acc: 0.9167\n",
      "Epoch 143/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.3094 - acc: 0.8956Epoch 00143: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.3094 - acc: 0.8957 - val_loss: 0.2790 - val_acc: 0.9110\n",
      "Epoch 144/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.3168 - acc: 0.8910Epoch 00144: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.3168 - acc: 0.8909 - val_loss: 0.2780 - val_acc: 0.9092\n",
      "Epoch 145/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.3138 - acc: 0.8924Epoch 00145: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.3131 - acc: 0.8925 - val_loss: 0.2634 - val_acc: 0.9141\n",
      "Epoch 146/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.3095 - acc: 0.8949Epoch 00146: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.3095 - acc: 0.8949 - val_loss: 0.2592 - val_acc: 0.9183\n",
      "Epoch 147/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.3080 - acc: 0.8935Epoch 00147: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.3092 - acc: 0.8927 - val_loss: 0.2692 - val_acc: 0.9137\n",
      "Epoch 148/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.3061 - acc: 0.8975Epoch 00148: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 98us/step - loss: 0.3058 - acc: 0.8980 - val_loss: 0.2596 - val_acc: 0.9184\n",
      "Epoch 149/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2971 - acc: 0.8985Epoch 00149: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2977 - acc: 0.8984 - val_loss: 0.2627 - val_acc: 0.9141\n",
      "Epoch 150/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.3071 - acc: 0.8956Epoch 00150: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 98us/step - loss: 0.3063 - acc: 0.8957 - val_loss: 0.2670 - val_acc: 0.9132\n",
      "Epoch 151/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.3120 - acc: 0.8959Epoch 00151: val_loss improved from 0.25905 to 0.25776, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 0.3116 - acc: 0.8960 - val_loss: 0.2578 - val_acc: 0.9153\n",
      "Epoch 152/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2995 - acc: 0.8965Epoch 00152: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2994 - acc: 0.8962 - val_loss: 0.2700 - val_acc: 0.9132\n",
      "Epoch 153/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2985 - acc: 0.9001Epoch 00153: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2986 - acc: 0.9001 - val_loss: 0.2675 - val_acc: 0.9128\n",
      "Epoch 154/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2932 - acc: 0.8993Epoch 00154: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 100us/step - loss: 0.2935 - acc: 0.8992 - val_loss: 0.2615 - val_acc: 0.9149\n",
      "Epoch 155/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2931 - acc: 0.8989Epoch 00155: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 100us/step - loss: 0.2938 - acc: 0.8988 - val_loss: 0.2618 - val_acc: 0.9143\n",
      "Epoch 156/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.3066 - acc: 0.8961Epoch 00156: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.3050 - acc: 0.8967 - val_loss: 0.2607 - val_acc: 0.9161\n",
      "Epoch 157/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2869 - acc: 0.9011Epoch 00157: val_loss improved from 0.25776 to 0.25523, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.2859 - acc: 0.9014 - val_loss: 0.2552 - val_acc: 0.9161\n",
      "Epoch 158/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2982 - acc: 0.8983Epoch 00158: val_loss improved from 0.25523 to 0.25212, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.2978 - acc: 0.8984 - val_loss: 0.2521 - val_acc: 0.9188\n",
      "Epoch 159/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2965 - acc: 0.8943Epoch 00159: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2965 - acc: 0.8947 - val_loss: 0.2592 - val_acc: 0.9179\n",
      "Epoch 160/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2952 - acc: 0.9006Epoch 00160: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2946 - acc: 0.9009 - val_loss: 0.2563 - val_acc: 0.9165\n",
      "Epoch 161/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2853 - acc: 0.9012Epoch 00161: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2859 - acc: 0.9013 - val_loss: 0.2578 - val_acc: 0.9169\n",
      "Epoch 162/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2861 - acc: 0.9029Epoch 00162: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2870 - acc: 0.9028 - val_loss: 0.2551 - val_acc: 0.9177\n",
      "Epoch 163/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2771 - acc: 0.9054Epoch 00163: val_loss improved from 0.25212 to 0.24839, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 0.2762 - acc: 0.9055 - val_loss: 0.2484 - val_acc: 0.9186\n",
      "Epoch 164/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2885 - acc: 0.9000Epoch 00164: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 98us/step - loss: 0.2887 - acc: 0.8998 - val_loss: 0.2575 - val_acc: 0.9161\n",
      "Epoch 165/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2932 - acc: 0.8994Epoch 00165: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2940 - acc: 0.8993 - val_loss: 0.2530 - val_acc: 0.9192\n",
      "Epoch 166/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2783 - acc: 0.9050Epoch 00166: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2774 - acc: 0.9051 - val_loss: 0.2488 - val_acc: 0.9204\n",
      "Epoch 167/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2726 - acc: 0.9065Epoch 00167: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2721 - acc: 0.9067 - val_loss: 0.2549 - val_acc: 0.9175\n",
      "Epoch 168/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2813 - acc: 0.9060Epoch 00168: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2816 - acc: 0.9058 - val_loss: 0.2529 - val_acc: 0.9183\n",
      "Epoch 169/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2757 - acc: 0.9065Epoch 00169: val_loss improved from 0.24839 to 0.24646, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 0.2748 - acc: 0.9067 - val_loss: 0.2465 - val_acc: 0.9190\n",
      "Epoch 170/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2673 - acc: 0.9103Epoch 00170: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2690 - acc: 0.9097 - val_loss: 0.2506 - val_acc: 0.9175\n",
      "Epoch 171/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2701 - acc: 0.9070Epoch 00171: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2696 - acc: 0.9071 - val_loss: 0.2571 - val_acc: 0.9190\n",
      "Epoch 172/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2708 - acc: 0.9048Epoch 00172: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 100us/step - loss: 0.2719 - acc: 0.9046 - val_loss: 0.2505 - val_acc: 0.9169\n",
      "Epoch 173/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2623 - acc: 0.9117Epoch 00173: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 100us/step - loss: 0.2639 - acc: 0.9114 - val_loss: 0.2517 - val_acc: 0.9220\n",
      "Epoch 174/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2791 - acc: 0.9052Epoch 00174: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2787 - acc: 0.9051 - val_loss: 0.2495 - val_acc: 0.9194\n",
      "Epoch 175/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2736 - acc: 0.9067Epoch 00175: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2755 - acc: 0.9062 - val_loss: 0.2534 - val_acc: 0.9143\n",
      "Epoch 176/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2712 - acc: 0.9072Epoch 00176: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2716 - acc: 0.9072 - val_loss: 0.2530 - val_acc: 0.9196\n",
      "Epoch 177/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2715 - acc: 0.9077Epoch 00177: val_loss improved from 0.24646 to 0.24508, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.2725 - acc: 0.9075 - val_loss: 0.2451 - val_acc: 0.9184\n",
      "Epoch 178/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2656 - acc: 0.9079Epoch 00178: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2648 - acc: 0.9080 - val_loss: 0.2475 - val_acc: 0.9214\n",
      "Epoch 179/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2704 - acc: 0.9077Epoch 00179: val_loss improved from 0.24508 to 0.24454, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.2695 - acc: 0.9080 - val_loss: 0.2445 - val_acc: 0.9218\n",
      "Epoch 180/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2615 - acc: 0.9108Epoch 00180: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 100us/step - loss: 0.2623 - acc: 0.9103 - val_loss: 0.2511 - val_acc: 0.9186\n",
      "Epoch 181/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2537 - acc: 0.9141Epoch 00181: val_loss improved from 0.24454 to 0.24421, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 0.2535 - acc: 0.9142 - val_loss: 0.2442 - val_acc: 0.9216\n",
      "Epoch 182/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2652 - acc: 0.9098Epoch 00182: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2652 - acc: 0.9100 - val_loss: 0.2445 - val_acc: 0.9212\n",
      "Epoch 183/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2567 - acc: 0.9120Epoch 00183: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2578 - acc: 0.9116 - val_loss: 0.2490 - val_acc: 0.9202\n",
      "Epoch 184/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2629 - acc: 0.9099Epoch 00184: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2628 - acc: 0.9098 - val_loss: 0.2515 - val_acc: 0.9196\n",
      "Epoch 185/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2555 - acc: 0.9114Epoch 00185: val_loss improved from 0.24421 to 0.24091, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.2543 - acc: 0.9118 - val_loss: 0.2409 - val_acc: 0.9224\n",
      "Epoch 186/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2476 - acc: 0.9166Epoch 00186: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2476 - acc: 0.9167 - val_loss: 0.2438 - val_acc: 0.9216\n",
      "Epoch 187/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2528 - acc: 0.9109- ETA: 0s - loss: 0.2537 - acc: 0.9Epoch 00187: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2535 - acc: 0.9110 - val_loss: 0.2451 - val_acc: 0.9192\n",
      "Epoch 188/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2566 - acc: 0.9109Epoch 00188: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 98us/step - loss: 0.2556 - acc: 0.9114 - val_loss: 0.2449 - val_acc: 0.9194\n",
      "Epoch 189/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2600 - acc: 0.9114Epoch 00189: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2602 - acc: 0.9114 - val_loss: 0.2451 - val_acc: 0.9228\n",
      "Epoch 190/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2504 - acc: 0.9129Epoch 00190: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2497 - acc: 0.9131 - val_loss: 0.2471 - val_acc: 0.9235\n",
      "Epoch 191/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2554 - acc: 0.9124Epoch 00191: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2552 - acc: 0.9125 - val_loss: 0.2451 - val_acc: 0.9204\n",
      "Epoch 192/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2530 - acc: 0.9149Epoch 00192: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2523 - acc: 0.9151 - val_loss: 0.2478 - val_acc: 0.9192\n",
      "Epoch 193/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2582 - acc: 0.9119Epoch 00193: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2581 - acc: 0.9123 - val_loss: 0.2499 - val_acc: 0.9192\n",
      "Epoch 194/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2383 - acc: 0.9187Epoch 00194: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2377 - acc: 0.9188 - val_loss: 0.2446 - val_acc: 0.9204\n",
      "Epoch 195/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2476 - acc: 0.9156Epoch 00195: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2477 - acc: 0.9155 - val_loss: 0.2431 - val_acc: 0.9230\n",
      "Epoch 196/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2419 - acc: 0.9163Epoch 00196: val_loss improved from 0.24091 to 0.23901, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 101us/step - loss: 0.2413 - acc: 0.9166 - val_loss: 0.2390 - val_acc: 0.9255\n",
      "Epoch 197/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2420 - acc: 0.9175Epoch 00197: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2423 - acc: 0.9173 - val_loss: 0.2453 - val_acc: 0.9228\n",
      "Epoch 198/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2398 - acc: 0.9171Epoch 00198: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2399 - acc: 0.9171 - val_loss: 0.2486 - val_acc: 0.9200\n",
      "Epoch 199/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2517 - acc: 0.9163Epoch 00199: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 98us/step - loss: 0.2512 - acc: 0.9164 - val_loss: 0.2490 - val_acc: 0.9204\n",
      "Epoch 200/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2465 - acc: 0.9170Epoch 00200: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2469 - acc: 0.9169 - val_loss: 0.2557 - val_acc: 0.9175\n",
      "Epoch 201/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2366 - acc: 0.9159Epoch 00201: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2368 - acc: 0.9162 - val_loss: 0.2468 - val_acc: 0.9198\n",
      "Epoch 202/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2411 - acc: 0.9168Epoch 00202: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2410 - acc: 0.9168 - val_loss: 0.2450 - val_acc: 0.9216\n",
      "Epoch 203/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2313 - acc: 0.9196Epoch 00203: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2317 - acc: 0.9193 - val_loss: 0.2437 - val_acc: 0.9222\n",
      "Epoch 204/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2431 - acc: 0.9155Epoch 00204: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2426 - acc: 0.9156 - val_loss: 0.2449 - val_acc: 0.9218\n",
      "Epoch 205/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2403 - acc: 0.9187Epoch 00205: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2410 - acc: 0.9184 - val_loss: 0.2499 - val_acc: 0.9224\n",
      "Epoch 206/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2386 - acc: 0.9165Epoch 00206: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2385 - acc: 0.9165 - val_loss: 0.2412 - val_acc: 0.9233\n",
      "Epoch 207/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2309 - acc: 0.9191Epoch 00207: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2309 - acc: 0.9188 - val_loss: 0.2457 - val_acc: 0.9228\n",
      "Epoch 208/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2426 - acc: 0.9184Epoch 00208: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2433 - acc: 0.9180 - val_loss: 0.2415 - val_acc: 0.9206\n",
      "Epoch 209/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2354 - acc: 0.9172Epoch 00209: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2355 - acc: 0.9171 - val_loss: 0.2397 - val_acc: 0.9230\n",
      "Epoch 210/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2273 - acc: 0.9210Epoch 00210: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2273 - acc: 0.9209 - val_loss: 0.2403 - val_acc: 0.9255\n",
      "Epoch 211/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2262 - acc: 0.9231Epoch 00211: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2275 - acc: 0.9229 - val_loss: 0.2424 - val_acc: 0.9243\n",
      "Epoch 212/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2208 - acc: 0.9256Epoch 00212: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 100us/step - loss: 0.2225 - acc: 0.9249 - val_loss: 0.2521 - val_acc: 0.9210\n",
      "Epoch 213/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2343 - acc: 0.9175Epoch 00213: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2357 - acc: 0.9176 - val_loss: 0.2453 - val_acc: 0.9214\n",
      "Epoch 214/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2299 - acc: 0.9233- ETA: 0s - loss: 0.2234 - acc:Epoch 00214: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2295 - acc: 0.9235 - val_loss: 0.2443 - val_acc: 0.9226\n",
      "Epoch 215/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2268 - acc: 0.9220Epoch 00215: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 100us/step - loss: 0.2260 - acc: 0.9222 - val_loss: 0.2393 - val_acc: 0.9251\n",
      "Epoch 216/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2342 - acc: 0.9209Epoch 00216: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 100us/step - loss: 0.2352 - acc: 0.9205 - val_loss: 0.2411 - val_acc: 0.9239\n",
      "Epoch 217/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2267 - acc: 0.9248Epoch 00217: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 100us/step - loss: 0.2274 - acc: 0.9246 - val_loss: 0.2413 - val_acc: 0.9235\n",
      "Epoch 218/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2284 - acc: 0.9233Epoch 00218: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 100us/step - loss: 0.2287 - acc: 0.9233 - val_loss: 0.2427 - val_acc: 0.9249\n",
      "Epoch 219/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2269 - acc: 0.9218Epoch 00219: val_loss improved from 0.23901 to 0.23830, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 0.2276 - acc: 0.9217 - val_loss: 0.2383 - val_acc: 0.9249\n",
      "Epoch 220/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2204 - acc: 0.9286Epoch 00220: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 100us/step - loss: 0.2208 - acc: 0.9284 - val_loss: 0.2428 - val_acc: 0.9245\n",
      "Epoch 221/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2208 - acc: 0.9217Epoch 00221: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 102us/step - loss: 0.2227 - acc: 0.9210 - val_loss: 0.2390 - val_acc: 0.9233\n",
      "Epoch 222/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2119 - acc: 0.9249Epoch 00222: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 100us/step - loss: 0.2117 - acc: 0.9251 - val_loss: 0.2503 - val_acc: 0.9206\n",
      "Epoch 223/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2262 - acc: 0.9236Epoch 00223: val_loss improved from 0.23830 to 0.23658, saving model to best_weights.hdf5\n",
      "11902/11902 [==============================] - 1s 103us/step - loss: 0.2270 - acc: 0.9230 - val_loss: 0.2366 - val_acc: 0.9241\n",
      "Epoch 224/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2141 - acc: 0.9267Epoch 00224: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 100us/step - loss: 0.2138 - acc: 0.9268 - val_loss: 0.2446 - val_acc: 0.9235\n",
      "Epoch 225/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2196 - acc: 0.9248Epoch 00225: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2193 - acc: 0.9249 - val_loss: 0.2442 - val_acc: 0.9224\n",
      "Epoch 226/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2192 - acc: 0.9222Epoch 00226: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2194 - acc: 0.9223 - val_loss: 0.2548 - val_acc: 0.9228\n",
      "Epoch 227/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2166 - acc: 0.9266Epoch 00227: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2171 - acc: 0.9266 - val_loss: 0.2459 - val_acc: 0.9196\n",
      "Epoch 228/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2143 - acc: 0.9261Epoch 00228: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2151 - acc: 0.9259 - val_loss: 0.2378 - val_acc: 0.9237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2207 - acc: 0.9259Epoch 00229: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2206 - acc: 0.9257 - val_loss: 0.2420 - val_acc: 0.9233\n",
      "Epoch 230/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2177 - acc: 0.9263Epoch 00230: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2175 - acc: 0.9264 - val_loss: 0.2397 - val_acc: 0.9226\n",
      "Epoch 231/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2282 - acc: 0.9210Epoch 00231: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 98us/step - loss: 0.2282 - acc: 0.9209 - val_loss: 0.2487 - val_acc: 0.9208\n",
      "Epoch 232/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2303 - acc: 0.9202Epoch 00232: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2306 - acc: 0.9203 - val_loss: 0.2458 - val_acc: 0.9220\n",
      "Epoch 233/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2142 - acc: 0.9273Epoch 00233: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 98us/step - loss: 0.2151 - acc: 0.9270 - val_loss: 0.2439 - val_acc: 0.9239\n",
      "Epoch 234/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2053 - acc: 0.9317Epoch 00234: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2058 - acc: 0.9315 - val_loss: 0.2382 - val_acc: 0.9230\n",
      "Epoch 235/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2076 - acc: 0.9308Epoch 00235: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2080 - acc: 0.9305 - val_loss: 0.2414 - val_acc: 0.9214\n",
      "Epoch 236/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2235 - acc: 0.9226Epoch 00236: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2238 - acc: 0.9226 - val_loss: 0.2395 - val_acc: 0.9237\n",
      "Epoch 237/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2140 - acc: 0.9264Epoch 00237: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2131 - acc: 0.9265 - val_loss: 0.2442 - val_acc: 0.9202\n",
      "Epoch 238/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2118 - acc: 0.9278Epoch 00238: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2111 - acc: 0.9281 - val_loss: 0.2421 - val_acc: 0.9230\n",
      "Epoch 239/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2190 - acc: 0.9226Epoch 00239: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2191 - acc: 0.9227 - val_loss: 0.2371 - val_acc: 0.9251\n",
      "Epoch 240/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2112 - acc: 0.9274Epoch 00240: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2107 - acc: 0.9275 - val_loss: 0.2426 - val_acc: 0.9224\n",
      "Epoch 241/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2098 - acc: 0.9257Epoch 00241: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2108 - acc: 0.9255 - val_loss: 0.2390 - val_acc: 0.9253\n",
      "Epoch 242/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2026 - acc: 0.9316Epoch 00242: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2018 - acc: 0.9317 - val_loss: 0.2427 - val_acc: 0.9239\n",
      "Epoch 243/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2054 - acc: 0.9312Epoch 00243: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2052 - acc: 0.9311 - val_loss: 0.2437 - val_acc: 0.9243\n",
      "Epoch 244/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2104 - acc: 0.9250Epoch 00244: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2107 - acc: 0.9251 - val_loss: 0.2411 - val_acc: 0.9243\n",
      "Epoch 245/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2109 - acc: 0.9277Epoch 00245: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 100us/step - loss: 0.2121 - acc: 0.9274 - val_loss: 0.2416 - val_acc: 0.9232\n",
      "Epoch 246/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2040 - acc: 0.9311Epoch 00246: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2041 - acc: 0.9309 - val_loss: 0.2381 - val_acc: 0.9247\n",
      "Epoch 247/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2132 - acc: 0.9279Epoch 00247: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2127 - acc: 0.9280 - val_loss: 0.2461 - val_acc: 0.9212\n",
      "Epoch 248/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2143 - acc: 0.9271Epoch 00248: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 98us/step - loss: 0.2135 - acc: 0.9272 - val_loss: 0.2428 - val_acc: 0.9253\n",
      "Epoch 249/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2034 - acc: 0.9313Epoch 00249: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 99us/step - loss: 0.2033 - acc: 0.9314 - val_loss: 0.2472 - val_acc: 0.9206\n",
      "Epoch 250/250\n",
      "11776/11902 [============================>.] - ETA: 0s - loss: 0.2039 - acc: 0.9308Epoch 00250: val_loss did not improve\n",
      "11902/11902 [==============================] - 1s 100us/step - loss: 0.2035 - acc: 0.9310 - val_loss: 0.2458 - val_acc: 0.9222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd624a50438>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='best_weights.hdf5',verbose=1,save_best_only=True)\n",
    "model.fit(X_train.reshape(X_train.shape[0],20,40,1), to_categorical(y_train),\n",
    "          batch_size=256, epochs=250, verbose=1,validation_split=0.3,callbacks=[checkpointer] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('best_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accurac : 92.0681%\n"
     ]
    }
   ],
   "source": [
    "y_predictions = [np.argmax(model.predict(np.expand_dims(example,axis=0))) for example in X_test.reshape(X_test.shape[0],20,40,1)]\n",
    "\n",
    "accuracy =100*np.sum(np.array(y_predictions)==np.argmax( to_categorical(y_test),axis=1))/len(y_predictions)\n",
    "\n",
    "print ('test accurac : %.4f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test (path):\n",
    "    #path=r\"C:\\Users\\abdal_000\\Downloads\\data-set\\test\\audio\\clip_0a77ea19a.wav\"\n",
    "    mfcc_feature=convert_wave_to_mfcc(path)\n",
    "    #print(mfcc_feature.shape)\n",
    "    \n",
    "    pre=model.predict(mfcc_feature.reshape(1,20,40,1))\n",
    "    return np.argmax(pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clip_000044442.wav\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "audfiles=os.listdir(r\"C:\\Users\\abdal_000\\Downloads\\data-set\\test\\audio\")\n",
    "print (audfiles[0])\n",
    "with open('sample_submission.csv', 'w', newline='') as csvfile:\n",
    "    fieldnames=['fname','label']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    for audio in audfiles:\n",
    "        pred = test(r\"C:\\Users\\abdal_000\\Downloads\\data-set\\test\\audio\\\\\"+audio)\n",
    "        writer.writerow({'fname':audio,'label':labels[pred]})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
